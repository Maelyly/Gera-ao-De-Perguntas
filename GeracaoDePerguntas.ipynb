{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQVwWO8fhwDg"
      },
      "source": [
        "# Geração de Perguntas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zj_EGiynngUV"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zj0Y8t--m9gT",
        "outputId": "c6dc0355-2c32-417c-d0dc-7f21d483c3ee"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "2E219qajhgT2"
      },
      "outputs": [],
      "source": [
        "#Importando Dataset\n",
        "import pandas as pd\n",
        "\n",
        "test = pd.read_json('datasets/test.json')\n",
        "train = pd.read_json('datasets/train.json')\n",
        "\n",
        "teste_new = pd.read_json('datasets/train-v2.0.json')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UtET5s5OcRva"
      },
      "outputs": [],
      "source": [
        "train = train.iloc[:200,:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "CCb3lOU_dL_M",
        "outputId": "cfdfc84a-954c-4b88-ebb5-c5d011d3714f"
      },
      "outputs": [],
      "source": [
        "train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aO-TPrKUh8ac"
      },
      "source": [
        "## Análise do Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SN8Z5CbGiCz7",
        "outputId": "dfce2081-6627-4850-b002-6d3228102ed2"
      },
      "outputs": [],
      "source": [
        "teste = teste_new['data'][0]\n",
        "teste"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N83bwnMvxKut"
      },
      "outputs": [],
      "source": [
        "teste = teste['paragraphs']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wpXo4oO1xWV_",
        "outputId": "e212a124-2422-4a38-c098-32fc1803ccf1"
      },
      "outputs": [],
      "source": [
        "len(teste)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ckqotDtJymEN"
      },
      "outputs": [],
      "source": [
        "testeNew = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "E9nA4ML80AZc",
        "outputId": "1d31188d-3309-4d25-ca08-5d8d4a02dbcb"
      },
      "outputs": [],
      "source": [
        "teste[0]['qas'][0]['question']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fqh6IraF37HL",
        "outputId": "3b53c343-b7b8-4180-a87f-becd7e30195c"
      },
      "outputs": [],
      "source": [
        "teste[2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FibEKN1lx8L_"
      },
      "outputs": [],
      "source": [
        "for item in teste:\n",
        "  for i in item['qas']:\n",
        "    testeNew.append([i['question'],i['answers']])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nApf01kq1Yn7",
        "outputId": "ea0c905f-d97a-4d94-d046-1f4883c730ec"
      },
      "outputs": [],
      "source": [
        "testeNew"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vkzY4J4EzR73"
      },
      "outputs": [],
      "source": [
        "testeNew = pd.DataFrame(testeNew)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "LoZNsgWy00Yo",
        "outputId": "3cc3cf93-64e0-47c6-cddc-1fae62880e05"
      },
      "outputs": [],
      "source": [
        "testeNew.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_S9o70gF080x"
      },
      "outputs": [],
      "source": [
        "testeNew.rename(columns={0: 'question'}, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Y-VDs3P1qMJ"
      },
      "outputs": [],
      "source": [
        "testeNew.rename(columns={1: 'answer'}, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tbY1TdWw1xRE"
      },
      "outputs": [],
      "source": [
        "def replaceAnswer(testeNew):\n",
        "  for i in testeNew:\n",
        "    i = i['text']\n",
        "    return i"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8aiEtCmi2vhN"
      },
      "outputs": [],
      "source": [
        "testeNew['answer'] = testeNew['answer'].apply(replaceAnswer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IIvry87G53CY"
      },
      "outputs": [],
      "source": [
        "context = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wgkoiy9R30IU"
      },
      "outputs": [],
      "source": [
        "for item in teste:\n",
        "  for i in item['qas']:\n",
        "    context.append(item['context'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yEbQ5-TU6LDI"
      },
      "outputs": [],
      "source": [
        "testeNew['context'] = context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Uwzwvb0O3dgq",
        "outputId": "99983702-c03f-4262-990d-3c994eaaded4"
      },
      "outputs": [],
      "source": [
        "testeNew.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pS_FVNNd8k8q"
      },
      "outputs": [],
      "source": [
        "testeNew.to_csv(\"testeNovo.csv\", encoding = 'utf-8')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRu934VF7gXh"
      },
      "source": [
        "### Analisando relação de frequência com resposta correta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLbDvjeoAJk8",
        "outputId": "a626eaa0-a416-41fb-e694-f71cf9c74eaa"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EtM3LgvzCzHu",
        "outputId": "182b7645-a526-446f-d5d8-423bb35fee04"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "tokenized_word=word_tokenize(train['support'][10])\n",
        "print(tokenized_word)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdoW9OOuCRAq",
        "outputId": "2406d3ed-bf9e-4970-f40f-0aab73a654c8"
      },
      "outputs": [],
      "source": [
        "from nltk.probability import FreqDist\n",
        "fdist = FreqDist(tokenized_word)\n",
        "print(fdist)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Axsne3n-CeMG",
        "outputId": "d5e97f51-b512-4bc3-dbe6-949fae3fecae"
      },
      "outputs": [],
      "source": [
        "fdist.most_common(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "XeRvNtPPDVjr",
        "outputId": "957f476b-3214-40f1-a549-d093038d1f8b"
      },
      "outputs": [],
      "source": [
        "train['support'][10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "bqJnv9HxDbgz",
        "outputId": "d2d051bd-7eee-4dfb-899e-2546c0e1ca38"
      },
      "outputs": [],
      "source": [
        "train['correct_answer'][10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "dc5-BjyQCpyr",
        "outputId": "dbffb007-f113-4b3e-9fa5-20505e69e15f"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fdist.plot(30,cumulative=False)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n4BPg-oTV5QQ"
      },
      "outputs": [],
      "source": [
        "def wordContains(fdist,correct):\n",
        "  a = correct\n",
        "  num = 0\n",
        "  correctLen = 1\n",
        "  for item in fdist.most_common(30):\n",
        "      if item[0] in a:\n",
        "        print('Contem: ')\n",
        "        print(item[0])\n",
        "        num = num + 1\n",
        "  print(a)\n",
        "  print(num)\n",
        "  if len(correct.split()) != 0:\n",
        "    correctLen = len(correct.split())\n",
        "  return num/correctLen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-RhVyvcfWDMF",
        "outputId": "906994f6-29af-4285-b834-38653bef9958"
      },
      "outputs": [],
      "source": [
        "response = []\n",
        "for num in range(0,len(train.index)):\n",
        "  tokenized_word=word_tokenize(train['support'][num])\n",
        "  fdist = FreqDist(tokenized_word)\n",
        "\n",
        "  response.append(wordContains(fdist,train['correct_answer'][num]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNn0kWLKelrn",
        "outputId": "6a606bed-5913-455f-aca2-32d8d38094a1"
      },
      "outputs": [],
      "source": [
        "response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVz7KoKfgBUS",
        "outputId": "4d71ac80-a685-495d-83e5-e04619cb8689"
      },
      "outputs": [],
      "source": [
        "sum(response)/len(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "24UTN9zcgBqH",
        "outputId": "82120caa-a8e9-4ce3-c03a-59145cfe1596"
      },
      "outputs": [],
      "source": [
        "plt.plot(response)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TuwAO-37gqAC"
      },
      "outputs": [],
      "source": [
        "train['Support_Most_Frequent_Correct_Answer_'] = response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "9Cd509oDg3Cl",
        "outputId": "759d5c1f-597c-4f0f-8b6d-75b5585c611d"
      },
      "outputs": [],
      "source": [
        "train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSW6_eOE7s5N"
      },
      "source": [
        "### Analisando similaridades"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q66eelU5ubS0",
        "outputId": "c8b8c267-6791-4d6a-ae07-b235bca6cfab"
      },
      "outputs": [],
      "source": [
        "!pip install spacy\n",
        "!spacy download en\n",
        "!spacy download en_core_web_lg\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onMTAb6b2azd",
        "outputId": "63212a31-0228-4498-c7bd-b155805eff82"
      },
      "outputs": [],
      "source": [
        "#Analisando similaridade das perguntas com o texto de apoio e com as respostas\n",
        "import numpy as np\n",
        "import spacy\n",
        "nlp = spacy.load('en_core_web_lg')\n",
        "a = nlp(train['question'][3])\n",
        "b = nlp(train['support'][3])\n",
        "c = nlp(train['correct_answer'][3])\n",
        "d = nlp(train['distractor1'][3])\n",
        "e = nlp(train['distractor2'][3])\n",
        "f = nlp(train['distractor3'][3])\n",
        "\n",
        "print('Similaridades: ')\n",
        "print('Pergunta com texto de apoio')\n",
        "print(a.similarity(b))\n",
        "print('Pergunta com resposta correta')\n",
        "print(a.similarity(c))\n",
        "print('Texto de apoio com resposta correta')\n",
        "print(b.similarity(c))\n",
        "print('Texto de apoio com resposta errada')\n",
        "print(b.similarity(d))\n",
        "print('Resposta correta com primeira resposta errada')\n",
        "print(c.similarity(d))\n",
        "print('Resposta correta com segunda resposta errada')\n",
        "print(c.similarity(e))\n",
        "print('Resposta correta com terceira resposta errada')\n",
        "print(c.similarity(f))\n",
        "print('Pergunta com resposta errada')\n",
        "print(a.similarity(d))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2aIuW9dN9knt"
      },
      "outputs": [],
      "source": [
        "def calc_similarity_mean(index,df):\n",
        "  ans = nlp(df['correct_answer'][index])\n",
        "  dis1 = nlp(df['distractor1'][index])\n",
        "  dis2 = nlp(df['distractor2'][index])\n",
        "  dis3 = nlp(df['distractor3'][index])\n",
        "\n",
        "  sim1 = ans.similarity(dis1)\n",
        "  sim2 = ans.similarity(dis2)\n",
        "  sim3 = ans.similarity(dis3)\n",
        "\n",
        "  return np.mean([sim1,sim2,sim3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7AYonZXP7x7o",
        "outputId": "4beb01b6-864e-4c2d-cf75-26189fe3d19d"
      },
      "outputs": [],
      "source": [
        "train['average_similarity'] = [calc_similarity_mean(ind,train) for ind in range(0,len(train['support']))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-lyUp4-k_6ef",
        "outputId": "6f6fe78c-2836-4c4c-e0fd-ad97d60fc706"
      },
      "outputs": [],
      "source": [
        "train['average_similarity']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "DIvvIgiMAjWE",
        "outputId": "1e348dad-9e76-43ad-9f45-32b6ec4b4281"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(train['average_similarity'].head(100))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZHCv2MCvW0D"
      },
      "source": [
        "## Processamento do texto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting sklearn\n",
            "  Downloading sklearn-0.0.tar.gz (1.1 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting scikit-learn\n",
            "  Using cached scikit_learn-1.1.2-cp310-cp310-win_amd64.whl (7.4 MB)\n",
            "Requirement already satisfied: scipy>=1.3.2 in d:\\arquivos de programas\\python\\python310\\lib\\site-packages (from scikit-learn->sklearn) (1.8.1)\n",
            "Requirement already satisfied: joblib>=1.0.0 in d:\\arquivos de programas\\python\\python310\\lib\\site-packages (from scikit-learn->sklearn) (1.2.0)\n",
            "Requirement already satisfied: numpy>=1.17.3 in d:\\arquivos de programas\\python\\python310\\lib\\site-packages (from scikit-learn->sklearn) (1.22.4)\n",
            "Collecting threadpoolctl>=2.0.0\n",
            "  Using cached threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
            "Building wheels for collected packages: sklearn\n",
            "  Building wheel for sklearn (setup.py): started\n",
            "  Building wheel for sklearn (setup.py): finished with status 'done'\n",
            "  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1310 sha256=b36bb4d04f0937d71b708ee1b2733979beb894a8399eed5960771672331746f1\n",
            "  Stored in directory: c:\\users\\matheus\\appdata\\local\\pip\\cache\\wheels\\9b\\13\\01\\6f3a7fd641f90e1f6c8c7cded057f3394f451f340371c68f3d\n",
            "Successfully built sklearn\n",
            "Installing collected packages: threadpoolctl, scikit-learn, sklearn\n",
            "Successfully installed scikit-learn-1.1.2 sklearn-0.0 threadpoolctl-3.1.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution -ip (d:\\arquivos de programas\\python\\python310\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ip (d:\\arquivos de programas\\python\\python310\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ip (d:\\arquivos de programas\\python\\python310\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ip (d:\\arquivos de programas\\python\\python310\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ip (d:\\arquivos de programas\\python\\python310\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ip (d:\\arquivos de programas\\python\\python310\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ip (d:\\arquivos de programas\\python\\python310\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ip (d:\\arquivos de programas\\python\\python310\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ip (d:\\arquivos de programas\\python\\python310\\lib\\site-packages)\n",
            "WARNING: You are using pip version 22.0.4; however, version 22.2.2 is available.\n",
            "You should consider upgrading via the 'D:\\Arquivos de Programas\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
          ]
        }
      ],
      "source": [
        "!pip install sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YW1netPTvbZW",
        "outputId": "c60b0291-f5c5-46fe-c4c0-1ec4e04a09c1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\Matheus\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\Matheus\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     C:\\Users\\Matheus\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package universal_tagset to\n",
            "[nltk_data]     C:\\Users\\Matheus\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Unzipping taggers\\universal_tagset.zip.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "import re\n",
        "import string\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize, TweetTokenizer, RegexpTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('universal_tagset')\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "\n",
        "\n",
        "vectorizer = TfidfVectorizer(use_idf=True,ngram_range=(1,2))\n",
        "\n",
        "def token(text):\n",
        "  text = text.translate(string.punctuation)\n",
        "  text = text.lower()\n",
        "  tokenizer = RegexpTokenizer(r'\\w+')\n",
        "  tokens = tokenizer.tokenize(text)\n",
        "\n",
        "  tokens = [word for word in tokens\n",
        "            if word not in stop_words\n",
        "                and len(word) > 3          \n",
        "                and not word[0].isdigit()]\n",
        "\n",
        "  return ' '.join(tokens)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "ZrQPPa-7uWM7"
      },
      "outputs": [],
      "source": [
        "def preprocess(text):\n",
        "  return token(text)\n",
        "\n",
        "#tokens_train = train['question'].apply(preprocess)\n",
        "\n",
        "#dataquestionstrain  = vectorizer.fit_transform(tokens_train)  \n",
        "\n",
        "#dataquestionstest = vectorizer.fit_transform(test['question'].apply(preprocess))\n",
        "\n",
        "#datatest = vectorizer.fit_transform(test['support'].apply(preprocess))\n",
        "\n",
        "#datatrain = vectorizer.fit_transform(test['support'].apply(preprocess))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfDkjkNRpO4j"
      },
      "source": [
        "### Aplicando preprocessamento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_9R5-xFy8Cdq"
      },
      "outputs": [],
      "source": [
        "df = train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iHFOKrOfpiQr"
      },
      "outputs": [],
      "source": [
        "df['support'] = train['support'].apply(preprocess)\n",
        "df['question'] = train['question'].apply(preprocess)\n",
        "df['correct_answer'] = train['correct_answer'].apply(preprocess)\n",
        "df['distractor1'] = train['distractor1'].apply(preprocess)\n",
        "df['distractor2'] = train['distractor2'].apply(preprocess)\n",
        "df['distractor3'] = train['distractor3'].apply(preprocess)\n",
        "\n",
        "\n",
        "df['support_pos'] = [nltk.pos_tag(i.split(),tagset='universal') for i in df['support']]\n",
        "df['question_pos'] = [nltk.pos_tag(i.split(),tagset='universal') for i in df['question']]\n",
        "df['correct_answer_pos'] = [nltk.pos_tag(i.split(),tagset='universal') for i in df['correct_answer']]\n",
        "df['distractor1_pos'] = [nltk.pos_tag(i.split(),tagset='universal') for i in df['distractor1']]\n",
        "df['distractor2_pos'] = [nltk.pos_tag(i.split(),tagset='universal') for i in df['distractor2']]\n",
        "df['distractor3_pos'] = [nltk.pos_tag(i.split(),tagset='universal') for i in df['distractor3']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "gNm9qzc3a1ee",
        "outputId": "e6bc7cd0-bf67-4b1c-c7d5-f48dfc0c7582"
      },
      "outputs": [],
      "source": [
        "train['question'][4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "OVwOvBpIZ3Hh",
        "outputId": "bd641f8d-0824-4e5f-e2f6-ebedaf51c4f2"
      },
      "outputs": [],
      "source": [
        "df['question'][4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YyN3YyY9Z-Rr",
        "outputId": "bb3e251b-7c62-40cf-e572-534ad9c038b0"
      },
      "outputs": [],
      "source": [
        "df['question_pos'][4]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p3BHy_CtBYs3"
      },
      "source": [
        "### Testando similaridade depois do preprocessamento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "ZQEwD8kOBfiZ",
        "outputId": "f1b7591b-e56d-4231-efd7-341a8a06d0ca"
      },
      "outputs": [],
      "source": [
        "df['average_similarity'] = [calc_similarity_mean(ind,df) for ind in range(0,len(df['support']))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "75JJlaxrDMSu"
      },
      "outputs": [],
      "source": [
        "plt.plot(df['average_similarity'].head(200))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPaWXGxZNfMt"
      },
      "source": [
        "## Geração de perguntas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7DFNSwyfFuu"
      },
      "source": [
        "**Baseado na implementação de:**\n",
        "\n",
        "Author: **Ramsri Goutham Golla**  [Linkedin](https://www.linkedin.com/in/ramsrig/)   [Twitter](https://twitter.com/ramsri_goutham/)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "BERT Word Sense Disambiguation is adapted from the awesome repo here. [BERT WSD](https://github.com/BPYap/BERT-WSD) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4q45GmGwVbT",
        "outputId": "27d50ad3-0f4e-4544-e987-ff89bb066d68"
      },
      "outputs": [],
      "source": [
        "!pip install --quiet transformers==2.9.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R07mVhsI4w45",
        "outputId": "1ec643a4-0590-48be-b7ed-67d56f28c2ba"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\Matheus\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to\n",
            "[nltk_data]     C:\\Users\\Matheus\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "from nltk.corpus import wordnet as wn\n",
        "\n",
        "sentence1 = \"Joana loves to watch cricket during his free time\"\n",
        "sentence2 = \"Joana is annoyed by a cricket in his room\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLt3WH3X5gJp",
        "outputId": "a3db1975-64fb-4c1a-8c58-e2932dc70db5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Synset('cricket.n.01') :  leaping insect; male makes chirping noises by rubbing the forewings together \n",
            "\n",
            "Synset('cricket.n.02') :  a game played with a ball and bat by two teams of 11 players; teams take turns trying to score runs \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# An example of a word with two different senses\n",
        "original_word = \"cricket\"\n",
        "\n",
        "syns = wn.synsets(original_word,'n')\n",
        "\n",
        "for syn in syns:\n",
        "  print (syn, \": \",syn.definition(),\"\\n\" )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nsxh1ZjF5d-j",
        "outputId": "b45881b9-1e65-44c9-c179-a8cf515d96e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "original word:  Cricket\n",
            "['Grasshopper']\n",
            "\n",
            "original word:  Cricket\n",
            "['Ball Game', 'Field Hockey', 'Football', 'Hurling', 'Lacrosse', 'Polo', 'Pushball', 'Ultimate Frisbee']\n"
          ]
        }
      ],
      "source": [
        "# Distractors from Wordnet\n",
        "def get_distractors_wordnet(syn,word):\n",
        "    distractors=[]\n",
        "    word= word.lower()\n",
        "    orig_word = word\n",
        "    if len(word.split())>0:\n",
        "        word = word.replace(\" \",\"_\")\n",
        "    hypernym = syn.hypernyms()\n",
        "    if len(hypernym) == 0: \n",
        "        return distractors\n",
        "    for item in hypernym[0].hyponyms():\n",
        "        name = item.lemmas()[0].name()\n",
        "        #print (\"name \",name, \" word\",orig_word)\n",
        "        if name == orig_word:\n",
        "            continue\n",
        "        name = name.replace(\"_\",\" \")\n",
        "        name = \" \".join(w.capitalize() for w in name.split())\n",
        "        if name is not None and name not in distractors:\n",
        "            distractors.append(name)\n",
        "    return distractors\n",
        "\n",
        "\n",
        "synset_to_use = wn.synsets(original_word,'n')[0]\n",
        "distractors_calculated = get_distractors_wordnet(synset_to_use,original_word)\n",
        "\n",
        "print (\"\\noriginal word: \",original_word.capitalize())\n",
        "print (distractors_calculated)\n",
        "\n",
        "\n",
        "original_word = \"cricket\"\n",
        "synset_to_use = wn.synsets(original_word,'n')[1]\n",
        "distractors_calculated = get_distractors_wordnet(synset_to_use,original_word)\n",
        "\n",
        "print (\"\\noriginal word: \",original_word.capitalize())\n",
        "print (distractors_calculated)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "neRbWQhO4GnG"
      },
      "source": [
        "### Download pretrained BERT WSD Model and extract"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rELsk4JIMhJ3"
      },
      "source": [
        "Download pre-trained BERT WSD from [here](https://entuedu-my.sharepoint.com/:f:/g/personal/boonpeng001_e_ntu_edu_sg/EiWzblOyyOBDtuO3klUbXoAB3THFzke-2MLWguIXrDopWg?e=08umXD)\n",
        "\n",
        "Click the download button at the top left of the link to download a file named \"bert_base-augmented-batch_size=128-lr=2e-5-max_gloss=6.zip\"\n",
        "\n",
        "Place the zip file in your Google drive home folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNz0zFZzrXqN",
        "outputId": "55eb1428-c51c-40de-c771-3887c017295d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "D:/Projects/BERT/bert_base-augmented-batch_size=128-lr=2e-5-max_gloss=6  is extracted already\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "bert_wsd_pytorch = \"D:/Projects/BERT/bert_base-augmented-batch_size=128-lr=2e-5-max_gloss=6.zip\"\n",
        "extract_directory = \"D:/Projects/BERT\"\n",
        "\n",
        "extracted_folder = bert_wsd_pytorch.replace(\".zip\",\"\")\n",
        "\n",
        "#  If unzipped folder exists don't unzip again.\n",
        "if not os.path.isdir(extracted_folder):\n",
        "  with zipfile.ZipFile(bert_wsd_pytorch, 'r') as zip_ref:\n",
        "      zip_ref.extractall(extract_directory)\n",
        "else:\n",
        "  print (extracted_folder,\" is extracted already\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GtYSH2ewtO4"
      },
      "source": [
        "### Find the correct sense (contextual meaning) of a given word in a sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EnmszaP9zSpe",
        "outputId": "e70b8eb5-647a-4759-ae67-5f7a5c7fe8d4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\Arquivos de Programas\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "C:\\Users\\Matheus\\AppData\\Local\\Temp\\ipykernel_3396\\775118080.py:24: UserWarning: Failed to initialize NumPy: module compiled against API version 0x10 but this version of numpy is 0xf (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:68.)\n",
            "  DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
            "Some weights of the model checkpoint at D:/Projects/BERT/bert_base-augmented-batch_size=128-lr=2e-5-max_gloss=6 were not used when initializing BertWSD: ['similarity_linear.weight', 'similarity_linear.bias', 'ranking_loss_factor', 'similarity_loss_factor']\n",
            "- This IS expected if you are initializing BertWSD from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertWSD from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "BertWSD(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30523, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (ranking_linear): Linear(in_features=768, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "import math\n",
        "from transformers import BertModel, BertConfig, BertPreTrainedModel, BertTokenizer\n",
        "\n",
        "class BertWSD(BertPreTrainedModel):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "\n",
        "        self.bert = BertModel(config)\n",
        "        self.dropout = torch.nn.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "        self.ranking_linear = torch.nn.Linear(config.hidden_size, 1)\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "\n",
        "# def _forward(args, model, batch):\n",
        "#     batch = tuple(t.to(args.device) for t in batch)\n",
        "#     outputs = model.bert(input_ids=batch[0], attention_mask=batch[1], token_type_ids=batch[2])\n",
        "\n",
        "#     return model.dropout(outputs[1])\n",
        "    \n",
        "\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model_dir = \"D:/Projects/BERT/bert_base-augmented-batch_size=128-lr=2e-5-max_gloss=6\"\n",
        "\n",
        "\n",
        "model = BertWSD.from_pretrained(model_dir)\n",
        "tokenizer = BertTokenizer.from_pretrained(model_dir)\n",
        "# add new special token\n",
        "if '[TGT]' not in tokenizer.additional_special_tokens:\n",
        "    tokenizer.add_special_tokens({'additional_special_tokens': ['[TGT]']})\n",
        "    assert '[TGT]' in tokenizer.additional_special_tokens\n",
        "    model.resize_token_embeddings(len(tokenizer))\n",
        "    \n",
        "model.to(DEVICE)\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0bWxo4vFUfH",
        "outputId": "a7af61b9-1b8f-4448-8731-e99187df17c1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\Matheus\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "import os\n",
        "from collections import namedtuple\n",
        "\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import wordnet as wn\n",
        "\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "\n",
        "GlossSelectionRecord = namedtuple(\"GlossSelectionRecord\", [\"guid\", \"sentence\", \"sense_keys\", \"glosses\", \"targets\"])\n",
        "BertInput = namedtuple(\"BertInput\", [\"input_ids\", \"input_mask\", \"segment_ids\", \"label_id\"])\n",
        "\n",
        "\n",
        "\n",
        "def _create_features_from_records(records, max_seq_length, tokenizer, cls_token_at_end=False, pad_on_left=False,\n",
        "                                  cls_token='[CLS]', sep_token='[SEP]', pad_token=0,\n",
        "                                  sequence_a_segment_id=0, sequence_b_segment_id=1,\n",
        "                                  cls_token_segment_id=1, pad_token_segment_id=0,\n",
        "                                  mask_padding_with_zero=True, disable_progress_bar=False):\n",
        "    \"\"\" Convert records to list of features. Each feature is a list of sub-features where the first element is\n",
        "        always the feature created from context-gloss pair while the rest of the elements are features created from\n",
        "        context-example pairs (if available)\n",
        "        `cls_token_at_end` define the location of the CLS token:\n",
        "            - False (Default, BERT/XLM pattern): [CLS] + A + [SEP] + B + [SEP]\n",
        "            - True (XLNet/GPT pattern): A + [SEP] + B + [SEP] + [CLS]\n",
        "        `cls_token_segment_id` define the segment id associated to the CLS token (0 for BERT, 2 for XLNet)\n",
        "    \"\"\"\n",
        "    features = []\n",
        "    for record in tqdm(records, disable=disable_progress_bar):\n",
        "        tokens_a = tokenizer.tokenize(record.sentence)\n",
        "\n",
        "        sequences = [(gloss, 1 if i in record.targets else 0) for i, gloss in enumerate(record.glosses)]\n",
        "\n",
        "        pairs = []\n",
        "        for seq, label in sequences:\n",
        "            tokens_b = tokenizer.tokenize(seq)\n",
        "\n",
        "            # Modifies `tokens_a` and `tokens_b` in place so that the total\n",
        "            # length is less than the specified length.\n",
        "            # Account for [CLS], [SEP], [SEP] with \"- 3\"\n",
        "            _truncate_seq_pair(tokens_a, tokens_b, max_seq_length - 3)\n",
        "\n",
        "            # The convention in BERT is:\n",
        "            # (a) For sequence pairs:\n",
        "            #  tokens:   [CLS] is this jack ##son ##ville ? [SEP] no it is not . [SEP]\n",
        "            #  type_ids:   0   0  0    0    0     0       0   0   1  1  1  1   1   1\n",
        "            #\n",
        "            # Where \"type_ids\" are used to indicate whether this is the first\n",
        "            # sequence or the second sequence. The embedding vectors for `type=0` and\n",
        "            # `type=1` were learned during pre-training and are added to the wordpiece\n",
        "            # embedding vector (and position vector). This is not *strictly* necessary\n",
        "            # since the [SEP] token unambiguously separates the sequences, but it makes\n",
        "            # it easier for the model to learn the concept of sequences.\n",
        "            #\n",
        "            # For classification tasks, the first vector (corresponding to [CLS]) is\n",
        "            # used as as the \"sentence vector\". Note that this only makes sense because\n",
        "            # the entire model is fine-tuned.\n",
        "            tokens = tokens_a + [sep_token]\n",
        "            segment_ids = [sequence_a_segment_id] * len(tokens)\n",
        "\n",
        "            tokens += tokens_b + [sep_token]\n",
        "            segment_ids += [sequence_b_segment_id] * (len(tokens_b) + 1)\n",
        "\n",
        "            if cls_token_at_end:\n",
        "                tokens = tokens + [cls_token]\n",
        "                segment_ids = segment_ids + [cls_token_segment_id]\n",
        "            else:\n",
        "                tokens = [cls_token] + tokens\n",
        "                segment_ids = [cls_token_segment_id] + segment_ids\n",
        "\n",
        "            input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "            # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
        "            # tokens are attended to.\n",
        "            input_mask = [1 if mask_padding_with_zero else 0] * len(input_ids)\n",
        "\n",
        "            # Zero-pad up to the sequence length.\n",
        "            padding_length = max_seq_length - len(input_ids)\n",
        "            if pad_on_left:\n",
        "                input_ids = ([pad_token] * padding_length) + input_ids\n",
        "                input_mask = ([0 if mask_padding_with_zero else 1] * padding_length) + input_mask\n",
        "                segment_ids = ([pad_token_segment_id] * padding_length) + segment_ids\n",
        "            else:\n",
        "                input_ids = input_ids + ([pad_token] * padding_length)\n",
        "                input_mask = input_mask + ([0 if mask_padding_with_zero else 1] * padding_length)\n",
        "                segment_ids = segment_ids + ([pad_token_segment_id] * padding_length)\n",
        "\n",
        "            assert len(input_ids) == max_seq_length\n",
        "            assert len(input_mask) == max_seq_length\n",
        "            assert len(segment_ids) == max_seq_length\n",
        "\n",
        "            pairs.append(\n",
        "                BertInput(input_ids=input_ids, input_mask=input_mask, segment_ids=segment_ids, label_id=label)\n",
        "            )\n",
        "\n",
        "        features.append(pairs)\n",
        "\n",
        "    return features\n",
        "\n",
        "\n",
        "def _truncate_seq_pair(tokens_a, tokens_b, max_length):\n",
        "    \"\"\"Truncates a sequence pair in place to the maximum length.\"\"\"\n",
        "\n",
        "    # This is a simple heuristic which will always truncate the longer sequence\n",
        "    # one token at a time. This makes more sense than truncating an equal percent\n",
        "    # of tokens from each, since if one sequence is very short then each token\n",
        "    # that's truncated likely contains more information than a longer sequence.\n",
        "    while True:\n",
        "        total_length = len(tokens_a) + len(tokens_b)\n",
        "        if total_length <= max_length:\n",
        "            break\n",
        "        if len(tokens_a) > len(tokens_b):\n",
        "            tokens_a.pop()\n",
        "        else:\n",
        "            tokens_b.pop()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJSpZRuOF-52",
        "outputId": "458a99a1-6377-45be-9e4d-1a260a08ed26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "aqui 1\n",
            "aqui 1\n",
            "aqui 1\n",
            "aqui 1\n",
            "aqui 1\n",
            "aqui 1\n",
            "aqui 1\n",
            "aqui 1\n",
            "aqui 1\n",
            "aqui 1\n",
            "aqui 2\n"
          ]
        },
        {
          "ename": "IndexError",
          "evalue": "index out of range in self",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32md:\\Projects\\Geracao-De-Perguntas\\GeracaoDePerguntas.ipynb Célula: 74\u001b[0m in \u001b[0;36m<cell line: 77>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/Geracao-De-Perguntas/GeracaoDePerguntas.ipynb#Y366sZmlsZQ%3D%3D?line=74'>75</a>\u001b[0m sentence_for_bert \u001b[39m=\u001b[39m sentence1\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m**\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39m [TGT] \u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/Geracao-De-Perguntas/GeracaoDePerguntas.ipynb#Y366sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m sentence_for_bert \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(sentence_for_bert\u001b[39m.\u001b[39msplit())\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Projects/Geracao-De-Perguntas/GeracaoDePerguntas.ipynb#Y366sZmlsZQ%3D%3D?line=76'>77</a>\u001b[0m sense,meaning,answer \u001b[39m=\u001b[39m get_sense(sentence_for_bert)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/Geracao-De-Perguntas/GeracaoDePerguntas.ipynb#Y366sZmlsZQ%3D%3D?line=78'>79</a>\u001b[0m \u001b[39mprint\u001b[39m (sentence1)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/Geracao-De-Perguntas/GeracaoDePerguntas.ipynb#Y366sZmlsZQ%3D%3D?line=79'>80</a>\u001b[0m \u001b[39mprint\u001b[39m (sense)\n",
            "\u001b[1;32md:\\Projects\\Geracao-De-Perguntas\\GeracaoDePerguntas.ipynb Célula: 74\u001b[0m in \u001b[0;36mget_sense\u001b[1;34m(sent)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/Geracao-De-Perguntas/GeracaoDePerguntas.ipynb#Y366sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m \u001b[39m# for i, bert_input in tqdm(list(enumerate(features)), desc=\"Progress\"):\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/Geracao-De-Perguntas/GeracaoDePerguntas.ipynb#Y366sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, bert_input \u001b[39min\u001b[39;00m \u001b[39mlist\u001b[39m(\u001b[39menumerate\u001b[39m(features)):\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/Geracao-De-Perguntas/GeracaoDePerguntas.ipynb#Y366sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m     logits[i] \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mranking_linear(\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Projects/Geracao-De-Perguntas/GeracaoDePerguntas.ipynb#Y366sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m         model\u001b[39m.\u001b[39;49mbert(\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/Geracao-De-Perguntas/GeracaoDePerguntas.ipynb#Y366sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m             input_ids\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mtensor(bert_input\u001b[39m.\u001b[39;49minput_ids, dtype\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mlong)\u001b[39m.\u001b[39;49munsqueeze(\u001b[39m0\u001b[39;49m)\u001b[39m.\u001b[39;49mto(DEVICE),\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/Geracao-De-Perguntas/GeracaoDePerguntas.ipynb#Y366sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m             attention_mask\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mtensor(bert_input\u001b[39m.\u001b[39;49minput_mask, dtype\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mlong)\u001b[39m.\u001b[39;49munsqueeze(\u001b[39m0\u001b[39;49m)\u001b[39m.\u001b[39;49mto(DEVICE),\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/Geracao-De-Perguntas/GeracaoDePerguntas.ipynb#Y366sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m             token_type_ids\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mtensor(bert_input\u001b[39m.\u001b[39;49msegment_ids, dtype\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mlong)\u001b[39m.\u001b[39;49munsqueeze(\u001b[39m0\u001b[39;49m)\u001b[39m.\u001b[39;49mto(DEVICE)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/Geracao-De-Perguntas/GeracaoDePerguntas.ipynb#Y366sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m         )[\u001b[39m1\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/Geracao-De-Perguntas/GeracaoDePerguntas.ipynb#Y366sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m     )\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/Geracao-De-Perguntas/GeracaoDePerguntas.ipynb#Y366sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m scores \u001b[39m=\u001b[39m softmax(logits, dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/Geracao-De-Perguntas/GeracaoDePerguntas.ipynb#Y366sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m preds \u001b[39m=\u001b[39m (\u001b[39msorted\u001b[39m(\u001b[39mzip\u001b[39m(sense_keys, definitions, scores), key\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m x: x[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m], reverse\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m))\n",
            "File \u001b[1;32md:\\Arquivos de Programas\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[1;32md:\\Arquivos de Programas\\Python\\Python310\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1015\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1008\u001b[0m \u001b[39m# Prepare head mask if needed\u001b[39;00m\n\u001b[0;32m   1009\u001b[0m \u001b[39m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[0;32m   1010\u001b[0m \u001b[39m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[0;32m   1011\u001b[0m \u001b[39m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[0;32m   1012\u001b[0m \u001b[39m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[0;32m   1013\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m-> 1015\u001b[0m embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membeddings(\n\u001b[0;32m   1016\u001b[0m     input_ids\u001b[39m=\u001b[39;49minput_ids,\n\u001b[0;32m   1017\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[0;32m   1018\u001b[0m     token_type_ids\u001b[39m=\u001b[39;49mtoken_type_ids,\n\u001b[0;32m   1019\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[0;32m   1020\u001b[0m     past_key_values_length\u001b[39m=\u001b[39;49mpast_key_values_length,\n\u001b[0;32m   1021\u001b[0m )\n\u001b[0;32m   1022\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder(\n\u001b[0;32m   1023\u001b[0m     embedding_output,\n\u001b[0;32m   1024\u001b[0m     attention_mask\u001b[39m=\u001b[39mextended_attention_mask,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1032\u001b[0m     return_dict\u001b[39m=\u001b[39mreturn_dict,\n\u001b[0;32m   1033\u001b[0m )\n\u001b[0;32m   1034\u001b[0m sequence_output \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n",
            "File \u001b[1;32md:\\Arquivos de Programas\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[1;32md:\\Arquivos de Programas\\Python\\Python310\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:239\u001b[0m, in \u001b[0;36mBertEmbeddings.forward\u001b[1;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[0;32m    236\u001b[0m         token_type_ids \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros(input_shape, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mlong, device\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mposition_ids\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m    238\u001b[0m \u001b[39mif\u001b[39;00m inputs_embeds \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 239\u001b[0m     inputs_embeds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mword_embeddings(input_ids)\n\u001b[0;32m    240\u001b[0m token_type_embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtoken_type_embeddings(token_type_ids)\n\u001b[0;32m    242\u001b[0m embeddings \u001b[39m=\u001b[39m inputs_embeds \u001b[39m+\u001b[39m token_type_embeddings\n",
            "File \u001b[1;32md:\\Arquivos de Programas\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[1;32md:\\Arquivos de Programas\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\sparse.py:158\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 158\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49membedding(\n\u001b[0;32m    159\u001b[0m         \u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding_idx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_norm,\n\u001b[0;32m    160\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnorm_type, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscale_grad_by_freq, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msparse)\n",
            "File \u001b[1;32md:\\Arquivos de Programas\\Python\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2199\u001b[0m, in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   2193\u001b[0m     \u001b[39m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[0;32m   2194\u001b[0m     \u001b[39m# XXX: equivalent to\u001b[39;00m\n\u001b[0;32m   2195\u001b[0m     \u001b[39m# with torch.no_grad():\u001b[39;00m\n\u001b[0;32m   2196\u001b[0m     \u001b[39m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[0;32m   2197\u001b[0m     \u001b[39m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[0;32m   2198\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[39minput\u001b[39m, max_norm, norm_type)\n\u001b[1;32m-> 2199\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49membedding(weight, \u001b[39minput\u001b[39;49m, padding_idx, scale_grad_by_freq, sparse)\n",
            "\u001b[1;31mIndexError\u001b[0m: index out of range in self"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import torch\n",
        "from tabulate import tabulate\n",
        "from torch.nn.functional import softmax\n",
        "from tqdm import tqdm\n",
        "from transformers import BertTokenizer\n",
        "import time\n",
        "\n",
        "\n",
        "MAX_SEQ_LENGTH = 128\n",
        "\n",
        "def get_sense(sent):\n",
        "  re_result = re.search(r\"\\[TGT\\](.*)\\[TGT\\]\", sent)\n",
        "  if re_result is None:\n",
        "      print(\"\\nIncorrect input format. Please try again.\")\n",
        "\n",
        "  ambiguous_word = re_result.group(1).strip()\n",
        "\n",
        "  results = dict()\n",
        "\n",
        "  wn_pos = wn.NOUN\n",
        "  \n",
        "  try: \n",
        "    for i, synset in enumerate(set(wn.synsets(ambiguous_word, pos=wn_pos))):\n",
        "        results[synset] =  synset.definition()\n",
        "        print(\"aqui 1\")\n",
        "  except:\n",
        "    print('problema no enum')\n",
        "\n",
        "  if len(results) ==0:\n",
        "    return (None,None,ambiguous_word)\n",
        "\n",
        "  print('aqui 2')\n",
        "  sense_keys=[]\n",
        "  definitions=[]\n",
        "  for sense_key, definition in results.items():\n",
        "      sense_keys.append(sense_key)\n",
        "      definitions.append(definition)\n",
        "\n",
        "\n",
        "  record = GlossSelectionRecord(\"test\", sent, sense_keys, definitions, [-1])\n",
        "\n",
        "  features = _create_features_from_records([record], MAX_SEQ_LENGTH, tokenizer,\n",
        "                                            cls_token=tokenizer.cls_token,\n",
        "                                            sep_token=tokenizer.sep_token,\n",
        "                                            cls_token_segment_id=1,\n",
        "                                            pad_token_segment_id=0,\n",
        "                                            disable_progress_bar=True)[0]\n",
        "\n",
        "  with torch.no_grad():\n",
        "      logits = torch.zeros(len(definitions), dtype=torch.double).to(DEVICE)\n",
        "      # for i, bert_input in tqdm(list(enumerate(features)), desc=\"Progress\"):\n",
        "      for i, bert_input in list(enumerate(features)):\n",
        "          logits[i] = model.ranking_linear(\n",
        "              model.bert(\n",
        "                  input_ids=torch.tensor(bert_input.input_ids, dtype=torch.long).unsqueeze(0).to(DEVICE),\n",
        "                  attention_mask=torch.tensor(bert_input.input_mask, dtype=torch.long).unsqueeze(0).to(DEVICE),\n",
        "                  token_type_ids=torch.tensor(bert_input.segment_ids, dtype=torch.long).unsqueeze(0).to(DEVICE)\n",
        "              )[1]\n",
        "          )\n",
        "      scores = softmax(logits, dim=0)\n",
        "\n",
        "      preds = (sorted(zip(sense_keys, definitions, scores), key=lambda x: x[-1], reverse=True))\n",
        "\n",
        "\n",
        " \n",
        "  sense = preds[0][0]\n",
        "  meaning = preds[0][1]\n",
        "  return (sense,meaning,ambiguous_word)\n",
        "\n",
        "\n",
        "sentence1 = \"Srivatsan loves to watch cricket during his free **time**\"\n",
        "\n",
        "\n",
        "sentence_for_bert = sentence1.replace(\"**\",\" [TGT] \")\n",
        "sentence_for_bert = \" \".join(sentence_for_bert.split())\n",
        "sense,meaning,answer = get_sense(sentence_for_bert)\n",
        "\n",
        "print (sentence1)\n",
        "print (sense)\n",
        "print (meaning)\n",
        "\n",
        "sentence2 = \"Srivatsan is annoyed by a **cricket** in his room\"\n",
        "sentence_for_bert = sentence2.replace(\"**\",\" [TGT] \")\n",
        "sentence_for_bert = \" \".join(sentence_for_bert.split())\n",
        "sense,meaning,answer = get_sense(sentence_for_bert)\n",
        "\n",
        "print (\"\\n-------------------------------\")\n",
        "print (sentence2)\n",
        "print (sense)\n",
        "print (meaning)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vwg3jDQJYKCh"
      },
      "source": [
        "### Generate a question using context and answer with T5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sentencepiece in d:\\arquivos de programas\\python\\python310\\lib\\site-packages (0.1.97)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution -ip (d:\\arquivos de programas\\python\\python310\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ip (d:\\arquivos de programas\\python\\python310\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ip (d:\\arquivos de programas\\python\\python310\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ip (d:\\arquivos de programas\\python\\python310\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ip (d:\\arquivos de programas\\python\\python310\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ip (d:\\arquivos de programas\\python\\python310\\lib\\site-packages)\n",
            "WARNING: You are using pip version 22.0.4; however, version 22.2.2 is available.\n",
            "You should consider upgrading via the 'D:\\Arquivos de Programas\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
          ]
        }
      ],
      "source": [
        "!pip install datsets transformers[sentencepiece]\n",
        "!pip install sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289,
          "referenced_widgets": [
            "7624a7e57a1d4afa805d3bd056b87302",
            "2c1f524ff637458ebbbbb1ae68b7ec37",
            "ef78e8fd3fca44908e40b019f87b2ffd",
            "c525f76b23b94307a363bbabfcc91faa",
            "879e8c12f4ee414e8f6cb6bef81c7ffc",
            "a25920f9e3114702a3d45e8e031b1847",
            "a6ec3d4bea994e46b92f826daaef0116",
            "f71518d544b14042b1334af9398643b2",
            "b713fe2bf35042be80ec9d094c37ed22",
            "1dcbf501815547289892988f0dbc95d2",
            "b4d1de5fe18e4264b62a1c84aa5cd885",
            "e8ecfcccd4a34a06b1f2e0edaf05956d",
            "390b935c8e57498abc96f06ea7d41064",
            "c5ea38ead48e4d57bae264eab2ec7c6d",
            "45768b701ef140719652aeef9ca1a761",
            "eaeba73ac01a4c84951c8b8d91eed234",
            "a204fd4515564f0182b1bfd0b046eb4f",
            "fc986018e9db417680f149c525b4a3d1",
            "147dcf9efe1d4220972474453921b1bd",
            "f40982dc95f04db29b24348ab1a9b759",
            "0ef70eb2c968425b9b88651ec29b2317",
            "f9bef91a31674df0837afe26af6fa09f",
            "681a1ceeda4145c28b7c396ee925ed1a",
            "933667ecf233444f8ed7d307f1ec9984",
            "14e09b1da5974be093777b01b42ef451",
            "34e2f1d7ecb44be7bb1d6941024e72ba",
            "f9ac5bedd1d140bfbd93ebe89eeb0aeb",
            "7c0c9b40d09045e384030e114c76af54",
            "d95f152001e0423cb37960207e2cc99a",
            "f4c45c003a1b478a9c7a06c30a888dbf",
            "7d5b367a25644d33bb28dbcb140979fa",
            "d23605ded9644e72835d90774742f7cf",
            "367544636b414ce89c9692d8894203f8"
          ]
        },
        "id": "wyazTS9RJ46n",
        "outputId": "814885b6-475f-4edc-a694-ddd5b06bfec4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\Arquivos de Programas\\Python\\Python310\\lib\\site-packages\\transformers\\models\\t5\\tokenization_t5.py:164: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
            "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
            "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
            "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
            "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "d:\\Arquivos de Programas\\Python\\Python310\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2302: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "d:\\Arquivos de Programas\\Python\\Python310\\lib\\site-packages\\transformers\\models\\t5\\tokenization_t5.py:219: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "context: Srivatsan loves to watch cricket during his free time answer: cricket </s>\n",
            "<pad>  What sport does Srivatsan enjoy watching?</s>\n",
            "\n",
            "**************************************\n",
            "\n",
            "context: Srivatsan is annoyed by a cricket in his room answer: cricket </s>\n",
            "<pad>  What insect is in Srivatsan's room?</s>\n"
          ]
        }
      ],
      "source": [
        "from transformers import T5ForConditionalGeneration,T5Tokenizer\n",
        "\n",
        "question_model = T5ForConditionalGeneration.from_pretrained('ramsrigouthamg/t5_squad_v1')\n",
        "question_tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
        "\n",
        "def get_question(sentence,answer):\n",
        "  text = \"context: {} answer: {} </s>\".format(sentence,answer)\n",
        "  print (text)\n",
        "  max_len = 256\n",
        "  encoding = question_tokenizer.encode_plus(text,max_length=max_len, pad_to_max_length=True, return_tensors=\"pt\")\n",
        "\n",
        "  input_ids, attention_mask = encoding[\"input_ids\"], encoding[\"attention_mask\"]\n",
        "\n",
        "  outs = question_model.generate(input_ids=input_ids,\n",
        "                                  attention_mask=attention_mask,\n",
        "                                  early_stopping=True,\n",
        "                                  num_beams=5,\n",
        "                                  num_return_sequences=1,\n",
        "                                  no_repeat_ngram_size=2,\n",
        "                                  max_length=200)\n",
        "\n",
        "\n",
        "  dec = [question_tokenizer.decode(ids) for ids in outs]\n",
        "\n",
        "\n",
        "  Question = dec[0].replace(\"question:\",\"\")\n",
        "  Question= Question.strip()\n",
        "  return Question\n",
        "\n",
        "\n",
        "sentence1 = \"Srivatsan loves to watch cricket during his free **time**\"\n",
        "sentence2 = \"Srivatsan is annoyed by a **cricket** in his room\"\n",
        "\n",
        "\n",
        "answer = \"cricket\"\n",
        "\n",
        "sentence_for_T5 = sentence1.replace(\"**\",\" \")\n",
        "sentence_for_T5 = \" \".join(sentence_for_T5.split()) \n",
        "ques = get_question(sentence_for_T5,answer)\n",
        "print (ques)\n",
        "\n",
        "\n",
        "print (\"\\n**************************************\\n\")\n",
        "sentence_for_T5 = sentence2.replace(\"**\",\" \")\n",
        "sentence_for_T5 = \" \".join(sentence_for_T5.split()) \n",
        "ques = get_question(sentence_for_T5,answer)\n",
        "print (ques)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jQ1QK_zYCFu"
      },
      "source": [
        "### Putting it all together"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKbPKBjr-KTp",
        "outputId": "1cdc6b8f-5803-4ecc-854e-4d804a118cc8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "aqui 1\n",
            "aqui 1\n",
            "aqui 1\n",
            "aqui 1\n",
            "aqui 1\n",
            "aqui 1\n",
            "aqui 1\n",
            "aqui 1\n",
            "aqui 1\n",
            "aqui 1\n",
            "aqui 2\n",
            "context: Srivatsan loves to watch cricket during his free time answer: none </s>\n",
            "<pad>  How much time does Srivatsan spend watching cricket?</s>\n",
            "none\n",
            "['Word not found in Wordnet. So unable to extract distractors.']\n",
            "none\n",
            "\n",
            "\n",
            "aqui 1\n",
            "aqui 1\n",
            "aqui 2\n",
            "context: Srivatsan is annoyed by a cricket in his room answer: none </s>\n",
            "<pad>  How many crickets are in Srivatsan's room?</s>\n",
            "none\n",
            "['Word not found in Wordnet. So unable to extract distractors.']\n",
            "none\n"
          ]
        }
      ],
      "source": [
        "def getMCQs(sent):\n",
        "  if sent == '':\n",
        "    return ''\n",
        "  sentence_for_bert = sent.replace(\"**\",\" [TGT] \")\n",
        "  sentence_for_bert = \" \".join(sentence_for_bert.split())\n",
        " \n",
        "  try:\n",
        "    sense,meaning,answer = get_sense(sentence_for_bert)\n",
        "  except:    \n",
        "    sense = None\n",
        "    meaning = 'none'\n",
        "    answer = 'none'\n",
        "\n",
        "  if sense is not None:\n",
        "    distractors = get_distractors_wordnet(sense,answer)\n",
        "  else: \n",
        "    distractors = [\"Word not found in Wordnet. So unable to extract distractors.\"]\n",
        "  sentence_for_T5 = sent.replace(\"**\",\" \")\n",
        "  sentence_for_T5 = \" \".join(sentence_for_T5.split()) \n",
        "  ques = get_question(sentence_for_T5,answer)\n",
        "  return ques,answer,distractors,meaning\n",
        "\n",
        "\n",
        "\n",
        "print (\"\\n\")\n",
        "question,answer,distractors,meaning = getMCQs(sentence1)\n",
        "print (question)\n",
        "print (answer)\n",
        "print (distractors)\n",
        "print (meaning)\n",
        "\n",
        "print (\"\\n\")\n",
        "question,answer,distractors,meaning = getMCQs(sentence2)\n",
        "print (question)\n",
        "print (answer)\n",
        "print (distractors)\n",
        "print (meaning)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NI2Y7Qu4eUBq"
      },
      "source": [
        "**Few more examples with disambiguation words (word with contextual meanings)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gp0Sa7EVdqgf",
        "outputId": "18bec8da-d32e-40b6-afb1-8a27e6249d30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "aqui 1\n",
            "aqui 1\n",
            "aqui 1\n",
            "aqui 1\n",
            "aqui 1\n",
            "aqui 1\n",
            "aqui 1\n",
            "aqui 1\n",
            "aqui 1\n",
            "aqui 1\n",
            "aqui 2\n",
            "context: John went to river bank to cry answer: none </s>\n",
            "<pad>  How many tears did John have?</s>\n",
            "none\n",
            "['Word not found in Wordnet. So unable to extract distractors.']\n",
            "none\n"
          ]
        }
      ],
      "source": [
        "# More examples\n",
        "\n",
        "sentence = \"John went to river **bank** to cry\"\n",
        "# sentence = \"John went to deposit money in the **bank**\"\n",
        "\n",
        "# sentence = \"John bought a **mouse** for his computer.\"\n",
        "# sentence = \"John saw a **mouse** under his bed.\"\n",
        "\n",
        "\n",
        "print (\"\\n\")\n",
        "question,answer,distractors,meaning = getMCQs(sentence)\n",
        "print (question)\n",
        "print (answer)\n",
        "print (distractors)\n",
        "print (meaning)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACjuSOYUlqod"
      },
      "source": [
        "### Testando com nosso dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "VK9G8frXOnmG"
      },
      "outputs": [],
      "source": [
        "testeNew = pd.read_csv('testeNovo.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0NFL-CVolDjG",
        "outputId": "379157f5-d4df-478c-b427-d23db711d2fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw the release of Beyoncé's debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".\n"
          ]
        }
      ],
      "source": [
        "sentence3 = testeNew['context'][0]\n",
        "print(sentence3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sw0RCiCYmBAy",
        "outputId": "1a60fb3c-438a-48d9-e51f-0b1ae67c0cb3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\Matheus\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWBwjrBFlbFc",
        "outputId": "b23fefef-682d-4cf8-d85b-519985b4f8a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Beyoncé', 'Giselle', 'Knowles-Carter', '(', '/biːˈjɒnseɪ/', 'bee-YON-say', ')', '(', 'born', 'September', '4', ',', '1981', ')', 'is', 'an', 'American', 'singer', ',', 'songwriter', ',', 'record', 'producer', 'and', 'actress', '.', 'Born', 'and', 'raised', 'in', 'Houston', ',', 'Texas', ',', 'she', 'performed', 'in', 'various', 'singing', 'and', 'dancing', 'competitions', 'as', 'a', 'child', ',', 'and', 'rose', 'to', 'fame', 'in', 'the', 'late', '1990s', 'as', 'lead', 'singer', 'of', 'R', '&', 'B', 'girl-group', 'Destiny', \"'s\", 'Child', '.', 'Managed', 'by', 'her', 'father', ',', 'Mathew', 'Knowles', ',', 'the', 'group', 'became', 'one', 'of', 'the', 'world', \"'s\", 'best-selling', 'girl', 'groups', 'of', 'all', 'time', '.', 'Their', 'hiatus', 'saw', 'the', 'release', 'of', 'Beyoncé', \"'s\", 'debut', 'album', ',', 'Dangerously', 'in', 'Love', '(', '2003', ')', ',', 'which', 'established', 'her', 'as', 'a', 'solo', 'artist', 'worldwide', ',', 'earned', 'five', 'Grammy', 'Awards', 'and', 'featured', 'the', 'Billboard', 'Hot', '100', 'number-one', 'singles', '``', 'Crazy', 'in', 'Love', \"''\", 'and', '``', 'Baby', 'Boy', \"''\", '.']\n"
          ]
        }
      ],
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "tokenized_word=word_tokenize(testeNew['context'][0])\n",
        "print(tokenized_word)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRG2fuEClwWd",
        "outputId": "7772c613-0b1e-4789-d453-9768efd2da9f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<FreqDist with 95 samples and 139 outcomes>\n"
          ]
        }
      ],
      "source": [
        "from nltk.probability import FreqDist\n",
        "fdist = FreqDist(tokenized_word)\n",
        "print(fdist)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "as8ArLMhl2FV"
      },
      "outputs": [],
      "source": [
        "listCommun = fdist.most_common(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIkbwUXVl9d4",
        "outputId": "90e84f59-b47f-44f7-b3d2-d26f2fe073aa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(',', 11),\n",
              " ('and', 6),\n",
              " ('in', 5),\n",
              " ('the', 5),\n",
              " ('.', 4),\n",
              " ('of', 4),\n",
              " ('(', 3),\n",
              " (')', 3),\n",
              " ('as', 3),\n",
              " (\"'s\", 3)]"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "listCommun"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "nQ_6gLjdmNyT"
      },
      "outputs": [],
      "source": [
        "sentence3 = sentence3.replace('Beyoncé','**Beyoncé**')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "JQoTSHxEcJ9W",
        "outputId": "3744696b-c3af-459c-a078-242b5c46ad35"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'**Beyoncé** Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny\\'s Child. Managed by her father, Mathew Knowles, the group became one of the world\\'s best-selling girl groups of all time. Their hiatus saw the release of **Beyoncé**\\'s debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".'"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sentence3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iIgV34ynlAi3",
        "outputId": "a2849b8e-1776-41d1-d084-2a415a9a4073"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "context: Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw the release of Beyoncé 's debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\". answer: Beyoncé [TGT] Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw the release of [TGT] Beyoncé </s>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\Arquivos de Programas\\Python\\Python310\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2302: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "question,answer,distractors,meaning = getMCQs(sentence3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "QuicznjfNoXc",
        "outputId": "2d87bb35-aeb1-41db-f95f-8614ed4fb54e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"<pad>  What is Beyoncé's full name?</s>\""
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "question"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "tMatmnxacrMz",
        "outputId": "2eefc809-4d04-45c1-ac28-f272d97b0e5a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"Beyoncé [TGT] Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw the release of [TGT] Beyoncé\""
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lkHjPGk6cx3Z",
        "outputId": "ebf626f0-5c38-4f18-e6dc-2404953728a7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Word not found in Wordnet. So unable to extract distractors.']"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "distractors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "ZPO_TcK3dADH"
      },
      "outputs": [],
      "source": [
        "meaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "JSRZKfv5dGs9"
      },
      "outputs": [],
      "source": [
        "testeNewPro = testeNew\n",
        "testeNewPro['context'] = testeNewPro['context'].apply(preprocess)\n",
        "\n",
        "# seed the pseudorandom number generator\n",
        "from random import seed\n",
        "from random import randint\n",
        "import random # necessário para utilizar o módulo random\n",
        "\n",
        "def mostUse(text):\n",
        "  if text == '':\n",
        "    return 'none'\n",
        "  new = text\n",
        "  tokenized_word=word_tokenize(new)\n",
        "  fdist = FreqDist(tokenized_word)\n",
        "  listCommun = fdist.most_common(10)\n",
        "  if listCommun[0] == 'n':\n",
        "    print(listCommun[0])\n",
        "  return listCommun[0]\n",
        "\n",
        "testeNewPro['mostUse'] = testeNewPro['context'].apply(mostUse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "id": "X8CtvQHCjeut",
        "outputId": "7967efcc-0e49-41b7-fb1f-f4d1c52bb3ea"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "      <th>context</th>\n",
              "      <th>mostUse</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>748</th>\n",
              "      <td>748</td>\n",
              "      <td>What crowdfunding platform was used in the con...</td>\n",
              "      <td>Catapult</td>\n",
              "      <td>december beyoncé along variety celebrities tea...</td>\n",
              "      <td>(campaign, 7)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>749</th>\n",
              "      <td>749</td>\n",
              "      <td>What is the name of the campaign that Beyoncé ...</td>\n",
              "      <td>Demand A Plan</td>\n",
              "      <td>december beyoncé along variety celebrities tea...</td>\n",
              "      <td>(campaign, 7)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>750</th>\n",
              "      <td>750</td>\n",
              "      <td>What school shooting prompted the creation of ...</td>\n",
              "      <td>Sandy Hook Elementary School</td>\n",
              "      <td>december beyoncé along variety celebrities tea...</td>\n",
              "      <td>(campaign, 7)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>751</th>\n",
              "      <td>751</td>\n",
              "      <td>What song did Beyoncé donate to the 2012 World...</td>\n",
              "      <td>I Was Here</td>\n",
              "      <td>december beyoncé along variety celebrities tea...</td>\n",
              "      <td>(campaign, 7)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>752</th>\n",
              "      <td>752</td>\n",
              "      <td>Who did Beyoncé work with in 2013 on the Chime...</td>\n",
              "      <td>Salma Hayek and Frida Giannini</td>\n",
              "      <td>december beyoncé along variety celebrities tea...</td>\n",
              "      <td>(campaign, 7)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Unnamed: 0                                           question  \\\n",
              "748         748  What crowdfunding platform was used in the con...   \n",
              "749         749  What is the name of the campaign that Beyoncé ...   \n",
              "750         750  What school shooting prompted the creation of ...   \n",
              "751         751  What song did Beyoncé donate to the 2012 World...   \n",
              "752         752  Who did Beyoncé work with in 2013 on the Chime...   \n",
              "\n",
              "                             answer  \\\n",
              "748                        Catapult   \n",
              "749                   Demand A Plan   \n",
              "750    Sandy Hook Elementary School   \n",
              "751                      I Was Here   \n",
              "752  Salma Hayek and Frida Giannini   \n",
              "\n",
              "                                               context        mostUse  \n",
              "748  december beyoncé along variety celebrities tea...  (campaign, 7)  \n",
              "749  december beyoncé along variety celebrities tea...  (campaign, 7)  \n",
              "750  december beyoncé along variety celebrities tea...  (campaign, 7)  \n",
              "751  december beyoncé along variety celebrities tea...  (campaign, 7)  \n",
              "752  december beyoncé along variety celebrities tea...  (campaign, 7)  "
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "testeNewPro.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6oZWcKamZEf",
        "outputId": "190348fb-5520-4655-97a9-40f526c6134f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('beyoncé', 2)"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "testeNewPro['mostUse'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "AWS2YDs-jrnn"
      },
      "outputs": [],
      "source": [
        "def replaceWords(text,support):\n",
        "  text = text.replace(\"'\",\"\")\n",
        "  if text == 'n':\n",
        "    return support.replace(text,(f\"**none**\"))\n",
        "  return support.replace(text,(f\"**{text}**\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LJhGY5pkacJ",
        "outputId": "e5d00355-3f7c-4fb4-80a2-fd01427b729d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Matheus\\AppData\\Local\\Temp\\ipykernel_3396\\3816747340.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  testeNewPro['context'][item] = replaceWords(testeNewPro['mostUse'][item][0],testeNewPro['context'][item])\n"
          ]
        }
      ],
      "source": [
        "#Ta surgindo um n nos most use, tentei tirar mas n ta indo vou fazer manual msm por enquanto\n",
        "for item in range (0,752):\n",
        "  testeNewPro['context'][item] = replaceWords(testeNewPro['mostUse'][item][0],testeNewPro['context'][item])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQBZL1zAoV5v",
        "outputId": "0647d7a3-627b-4a99-ae33-fc22c4975f8f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('beyoncé', 2)"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "testeNewPro['mostUse'][10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "NjkjR7auoeEB",
        "outputId": "9a22f8ad-819f-44ed-b856-5ba02205f9fe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'beyoncé'"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "testeNewPro['mostUse'][10][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78AwQ-3NdkXL",
        "outputId": "2f46048a-a05f-45d8-b12c-5e6d174a8d57"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([('beyoncé', 2), ('album', 4), ('artist', 5), ('beyoncé', 4),\n",
              "       ('school', 7), ('group', 7), ('group', 8), ('album', 5),\n",
              "       ('beyoncé', 5), ('destiny', 6), ('second', 3), ('film', 4),\n",
              "       ('video', 9), ('year', 4), ('birth', 2), ('beyoncé', 3),\n",
              "       ('beyoncé', 6), ('february', 1), ('august', 2), ('blue', 3),\n",
              "       ('april', 2), ('letter', 2), ('death', 2), ('million', 9),\n",
              "       ('vocal', 5), ('received', 2), ('number', 4), ('jackson', 4),\n",
              "       ('tour', 4), ('sasha', 5), ('fashion', 4), ('name', 3),\n",
              "       ('beyoncé', 7), ('single', 4), ('artist', 7), ('awards', 7),\n",
              "       ('topshop', 3), ('music', 5), ('deréon', 5), ('launch', 3),\n",
              "       ('hurricane', 2), ('campaign', 7)], dtype=object)"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "testeNewPro['mostUse'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "LSSrtoaNoNlz",
        "outputId": "4bd5d899-1269-4b08-ba67-38b9e4bd3849"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'**beyoncé** giselle knowles carter biːˈjɒnseɪ born september american singer songwriter record producer actress born raised houston texas performed various singing dancing competitions child rose fame late lead singer girl group destiny child managed father mathew knowles group became world best selling girl groups time hiatus release **beyoncé** debut album dangerously love established solo artist worldwide earned five grammy awards featured billboard number singles crazy love baby'"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "testeNewPro['context'][10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P32J5wDGu4hB",
        "outputId": "c96fd132-0ab3-4185-a69e-86567a7e14a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "context: beyoncé giselle knowles carter biːˈjɒnseɪ born september american singer songwriter record producer actress born raised houston texas performed various singing dancing competitions child rose fame late lead singer girl group destiny child managed father mathew knowles group became world best selling girl groups time hiatus release beyoncé debut album dangerously love established solo artist worldwide earned five grammy awards featured billboard number singles crazy love baby answer: beyoncé [TGT] giselle knowles carter biːˈjɒnseɪ born september american singer songwriter record producer actress born raised houston texas performed various singing dancing competitions child rose fame late lead singer girl group destiny child managed father mathew knowles group became world best selling girl groups time hiatus release [TGT] beyoncé </s>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\Arquivos de Programas\\Python\\Python310\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2302: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "d:\\Arquivos de Programas\\Python\\Python310\\lib\\site-packages\\transformers\\models\\t5\\tokenization_t5.py:219: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "question,answer, distractors,meaning = getMCQs(testeNewPro['context'][4])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "VJok3BMuvHJB",
        "outputId": "2956cd0d-1e05-454b-857b-9bd02611665c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"<pad>  What is the name of Beyonce's debut album dangerously love?</s>\""
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "question"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "hw_LXRUvvJUP",
        "outputId": "9e4b0250-e3f8-4cf8-812b-bcf0fcb4f17e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'beyoncé [TGT] giselle knowles carter biːˈjɒnseɪ born september american singer songwriter record producer actress born raised houston texas performed various singing dancing competitions child rose fame late lead singer girl group destiny child managed father mathew knowles group became world best selling girl groups time hiatus release [TGT] beyoncé'"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "8-Bjd7vXvR5J",
        "outputId": "657b4062-16ef-4b52-cf05-6aa2bfd2a85f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'In which decade did Beyonce become famous?'"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "testeNew['question'][4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "NtZ3rXUkvWSZ",
        "outputId": "3e4ebd0e-f6d4-4494-b36f-c4aba0562ffc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'late 1990s'"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "testeNew['answer'][4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PI4xElW8v6ck",
        "outputId": "38402813-38d3-4663-d234-a7e007db1466"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Word not found in Wordnet. So unable to extract distractors.']"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "distractors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kRi6NlzsLZWl",
        "outputId": "79b8b3cd-8487-455e-9441-70738917faf4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "753"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(testeNewPro['context'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dqjpr2lCNz4p",
        "outputId": "b4598a52-1e11-4cab-b274-cde4a3f66280"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('beyoncé', 5)"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "testeNewPro['mostUse'][703]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2PHDUrpBRaD"
      },
      "source": [
        "### teste"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vOV2P3Lv1QUU"
      },
      "outputs": [],
      "source": [
        "teste_Train = testeNewPro.iloc[:10,:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6h5xVIX1apg",
        "outputId": "c1e9eb2c-bf06-4588-d306-4d9675e8107a"
      },
      "outputs": [],
      "source": [
        "teste_Train['Newquestion'] = teste_Train['context'].apply(getMCQs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBSI2a8j6IGo",
        "outputId": "4f6a3c8b-c7a3-4aea-f6a2-6aa8defdd6f2"
      },
      "outputs": [],
      "source": [
        "teste_Train['Newquestion'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "izpYlxvG3t4D"
      },
      "outputs": [],
      "source": [
        "for i in teste_Train['Newquestion']:\n",
        "  if \"Word not found in Wordnet\" not in i[2][0]:\n",
        "    print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2axqIEn07HXa"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xRCWw2J3p3Hn",
        "outputId": "43c22da8-a317-4687-d131-39c24295668b"
      },
      "outputs": [],
      "source": [
        "testeNewPro['Newquestion'] = testeNewPro['context'].apply(getMCQs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "id": "BoJCDCf-rV2E",
        "outputId": "7208d67b-8c1c-495b-e390-4acd94250718"
      },
      "outputs": [],
      "source": [
        "testeNewPro.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z1osiVPugxGV"
      },
      "outputs": [],
      "source": [
        "listQ = []\n",
        "for item in testeNewPro['Newquestion']:\n",
        "  if item[0] not in listQ:\n",
        "    listQ.append(item[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qgVn6PPGiUdT"
      },
      "outputs": [],
      "source": [
        "listR = []\n",
        "for item in testeNewPro['Newquestion']:\n",
        "  if item[1] not in listR:\n",
        "    listR.append(item[1])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B3DmQB78ixSM"
      },
      "outputs": [],
      "source": [
        "listTQ = []\n",
        "\n",
        "for item in testeNewPro['Newquestion']:\n",
        "  listTQ.append(item[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ju4M3FKZjQ17"
      },
      "outputs": [],
      "source": [
        "listTR = []\n",
        "\n",
        "for item in testeNewPro['Newquestion']:\n",
        "  listTR.append(item[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SOD2uNHzjWJ9"
      },
      "outputs": [],
      "source": [
        "testeNewPro['Question_Generate'] = listTQ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XZmQk_QOjrah"
      },
      "outputs": [],
      "source": [
        "def replaceTGT(text):\n",
        "   return text.replace(\"[TGT]\",'')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZhNwWEqXjbz5"
      },
      "outputs": [],
      "source": [
        "testeNewPro['Answer_Generate'] = listTR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M67w7zL_ktPX"
      },
      "outputs": [],
      "source": [
        "testeNewPro['Answer_Generate'] = testeNewPro['Answer_Generate'].apply(replaceTGT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "id": "HET1xYKAjfE0",
        "outputId": "605887c6-3f45-495a-906c-f222fc60b776"
      },
      "outputs": [],
      "source": [
        "testeNewPro.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2_j8z-fhbRM",
        "outputId": "b596d739-8b83-4f27-f953-7f0238586f62"
      },
      "outputs": [],
      "source": [
        "listQ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pAB_SfNLigCo",
        "outputId": "60def59e-d81c-46ae-a2db-390546554de4"
      },
      "outputs": [],
      "source": [
        "listR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4g6e20Pkf48z"
      },
      "outputs": [],
      "source": [
        "testeNewPro.to_csv(\"testeResultsClean.csv\", encoding = 'utf-8')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QgDCWf7_zyp"
      },
      "source": [
        "## Visualização inicial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mAW9lxRH_2pH"
      },
      "outputs": [],
      "source": [
        "!pip install pyLDAvis\n",
        "\n",
        "import pyLDAvis.sklearn\n",
        "import pyLDAvis\n",
        "import matplotlib.pyplot as plt\n",
        "#%matplotlib inline\n",
        "\n",
        "pyLDAvis.enable_notebook()\n",
        "# panel = pyLDAvis.sklearn.prepare(lda_model, \n",
        "#                                  tokens_nltk, \n",
        "#                                  vectorizer, \n",
        "#                                  mds='tsne', \n",
        "#                                 sort_topics=False )\n",
        "# panel\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.4 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "de7c37f11048604427e696a7e966b00a255ebcd16cd0a44f6d549979884e8d96"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0ef70eb2c968425b9b88651ec29b2317": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "147dcf9efe1d4220972474453921b1bd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14e09b1da5974be093777b01b42ef451": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4c45c003a1b478a9c7a06c30a888dbf",
            "max": 791656,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7d5b367a25644d33bb28dbcb140979fa",
            "value": 791656
          }
        },
        "1dcbf501815547289892988f0dbc95d2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c1f524ff637458ebbbbb1ae68b7ec37": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a25920f9e3114702a3d45e8e031b1847",
            "placeholder": "​",
            "style": "IPY_MODEL_a6ec3d4bea994e46b92f826daaef0116",
            "value": "Downloading: 100%"
          }
        },
        "34e2f1d7ecb44be7bb1d6941024e72ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d23605ded9644e72835d90774742f7cf",
            "placeholder": "​",
            "style": "IPY_MODEL_367544636b414ce89c9692d8894203f8",
            "value": " 792k/792k [00:00&lt;00:00, 1.08MB/s]"
          }
        },
        "367544636b414ce89c9692d8894203f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "390b935c8e57498abc96f06ea7d41064": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a204fd4515564f0182b1bfd0b046eb4f",
            "placeholder": "​",
            "style": "IPY_MODEL_fc986018e9db417680f149c525b4a3d1",
            "value": "Downloading: 100%"
          }
        },
        "45768b701ef140719652aeef9ca1a761": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ef70eb2c968425b9b88651ec29b2317",
            "placeholder": "​",
            "style": "IPY_MODEL_f9bef91a31674df0837afe26af6fa09f",
            "value": " 892M/892M [00:32&lt;00:00, 51.4MB/s]"
          }
        },
        "681a1ceeda4145c28b7c396ee925ed1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_933667ecf233444f8ed7d307f1ec9984",
              "IPY_MODEL_14e09b1da5974be093777b01b42ef451",
              "IPY_MODEL_34e2f1d7ecb44be7bb1d6941024e72ba"
            ],
            "layout": "IPY_MODEL_f9ac5bedd1d140bfbd93ebe89eeb0aeb"
          }
        },
        "7624a7e57a1d4afa805d3bd056b87302": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2c1f524ff637458ebbbbb1ae68b7ec37",
              "IPY_MODEL_ef78e8fd3fca44908e40b019f87b2ffd",
              "IPY_MODEL_c525f76b23b94307a363bbabfcc91faa"
            ],
            "layout": "IPY_MODEL_879e8c12f4ee414e8f6cb6bef81c7ffc"
          }
        },
        "7c0c9b40d09045e384030e114c76af54": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d5b367a25644d33bb28dbcb140979fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "879e8c12f4ee414e8f6cb6bef81c7ffc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "933667ecf233444f8ed7d307f1ec9984": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c0c9b40d09045e384030e114c76af54",
            "placeholder": "​",
            "style": "IPY_MODEL_d95f152001e0423cb37960207e2cc99a",
            "value": "Downloading: 100%"
          }
        },
        "a204fd4515564f0182b1bfd0b046eb4f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a25920f9e3114702a3d45e8e031b1847": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6ec3d4bea994e46b92f826daaef0116": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b4d1de5fe18e4264b62a1c84aa5cd885": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b713fe2bf35042be80ec9d094c37ed22": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c525f76b23b94307a363bbabfcc91faa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1dcbf501815547289892988f0dbc95d2",
            "placeholder": "​",
            "style": "IPY_MODEL_b4d1de5fe18e4264b62a1c84aa5cd885",
            "value": " 1.21k/1.21k [00:00&lt;00:00, 9.77kB/s]"
          }
        },
        "c5ea38ead48e4d57bae264eab2ec7c6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_147dcf9efe1d4220972474453921b1bd",
            "max": 891695056,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f40982dc95f04db29b24348ab1a9b759",
            "value": 891695056
          }
        },
        "d23605ded9644e72835d90774742f7cf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d95f152001e0423cb37960207e2cc99a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e8ecfcccd4a34a06b1f2e0edaf05956d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_390b935c8e57498abc96f06ea7d41064",
              "IPY_MODEL_c5ea38ead48e4d57bae264eab2ec7c6d",
              "IPY_MODEL_45768b701ef140719652aeef9ca1a761"
            ],
            "layout": "IPY_MODEL_eaeba73ac01a4c84951c8b8d91eed234"
          }
        },
        "eaeba73ac01a4c84951c8b8d91eed234": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef78e8fd3fca44908e40b019f87b2ffd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f71518d544b14042b1334af9398643b2",
            "max": 1208,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b713fe2bf35042be80ec9d094c37ed22",
            "value": 1208
          }
        },
        "f40982dc95f04db29b24348ab1a9b759": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f4c45c003a1b478a9c7a06c30a888dbf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f71518d544b14042b1334af9398643b2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9ac5bedd1d140bfbd93ebe89eeb0aeb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9bef91a31674df0837afe26af6fa09f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fc986018e9db417680f149c525b4a3d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
